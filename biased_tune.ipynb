{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "753f30c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu117'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usual imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f467dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('.', torch_dtype=torch.bfloat16).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad10b3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from the cache\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "540b725e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 3200, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-25): 26 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (k_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (v_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (o_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=3200, out_features=8640, bias=False)\n",
       "          (down_proj): Linear(in_features=8640, out_features=3200, bias=False)\n",
       "          (up_proj): Linear(in_features=3200, out_features=8640, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3200, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce2e2383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable grad\n",
    "for p in model.parameters():\n",
    "    p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4222e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasInjector(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.segment_bias = nn.Parameter(torch.randn(base_model.config.hidden_size) * 0.01)\n",
    "        self.command_token = nn.Parameter(torch.randn(1, 1, base_model.config.hidden_size) * 0.05)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        tokens = self.base_model.model.embed_tokens(input_ids)        \n",
    "        tokens = torch.cat((self.command_token, tokens), -2)\n",
    "        tokens = tokens + self.segment_bias\n",
    "        y = self.base_model(inputs_embeds=tokens, attention_mask=attention_mask)\n",
    "        return y\n",
    "\n",
    "biased = BiasInjector(base_model).cuda().to(model.config.torch_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31aba58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2+x=5\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def gen_up_to(txt, n, allow_nl=1):\n",
    "    model = biased\n",
    "    x = tokenizer(txt, return_tensors=\"pt\").input_ids.cuda()\n",
    "    nl = 13\n",
    "    res = []\n",
    "    for i in range(n):\n",
    "        y = model(x).logits[0][-1].argmax()\n",
    "        res.append(y)\n",
    "        if y == nl:\n",
    "            allow_nl -= 1\n",
    "            if allow_nl <= 0:\n",
    "                break\n",
    "        if y == tokenizer.eos_token_id:\n",
    "            break\n",
    "        x = F.pad(x, (0, 1), value=y)\n",
    "\n",
    "    return tokenizer.decode(res)\n",
    "\n",
    "gen_up_to(\"Q: Solve 2+x=5 for x.\\nA: \", 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b144fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim_fn = torch.optim.Adam(biased.parameters())\n",
    "\n",
    "def train_step(q, a):\n",
    "    model = biased\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "    expected = tokenizer(a, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    expected = expected.to(\"cuda\").input_ids[0]\n",
    "    prompt = tokenizer(q, return_tensors=\"pt\").to(\"cuda\").input_ids\n",
    "    \n",
    "    while len(expected) > 0:        \n",
    "        optim_fn.zero_grad()\n",
    "        ypred = model(prompt).logits[0][-1]    \n",
    "        loss = loss_fn(ypred, expected[0])        \n",
    "        loss.backward()\n",
    "        optim_fn.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        n += 1 \n",
    "        with torch.no_grad():\n",
    "            prompt = F.pad(prompt, (0, 1), value=expected[0])        \n",
    "\n",
    "        expected = expected[1:]\n",
    "        \n",
    "\n",
    "    return total_loss / max(n, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ade58b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbbfa9b2b1a34a0db381bac983385cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ae0c763b5f4091b334e829fd0b74b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.038041547355515\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def step():\n",
    "    l = 0\n",
    "    train = [\n",
    "        (\"Solve 2+x=5 for x.\", \"3\"),\n",
    "        (\"Capital of France\", \"Paris\"),\n",
    "        (\"The most famous pokemon owned by Ash\", \"Pikachu\"),\n",
    "        (\"Portable computer\", \"Laptop\"),\n",
    "        (\"If I have a red ball, then the color of my ball is\", \"red\"),\n",
    "        (\"Second color of the rainbow\", \"orange\"),\n",
    "        (\"Spain can be described as\", \"Spain (Spanish: España, [esˈpaɲa] (listen)), or the Kingdom of Spain (Reino de España),[f] is a country primarily located in Southwestern Europe, with parts of territory in the Atlantic Ocean and across the Mediterranean Sea.[11][g] The largest part of Spain is situated on the Iberian Peninsula; its territory also includes the Canary Islands in the Atlantic Ocean, the Balearic Islands in the Mediterranean Sea, and the autonomous cities of Ceuta and Melilla in Africa. The country's mainland is bordered to the north by France, Andorra and the Bay of Biscay; to the east and south by the Mediterranean Sea and Gibraltar; and to the west by Portugal and the Atlantic Ocean. It is the largest country in Southern Europe and the second-largest and fourth-most populous in the European Union. Spain's capital and largest city is Madrid; other major urban areas include Barcelona, Valencia, Zaragoza, Seville, Málaga, Murcia, Palma de Mallorca, Las Palmas de Gran Canaria, and Bilbao.\"),\n",
    "        (\"Crown can be described as\", \"A crown is a traditional form of head adornment, or hat, worn by monarchs as a symbol of their power and dignity. A crown is often, by extension, a symbol of the monarch's government or items endorsed by it. The word itself is used, particularly in Commonwealth countries, as an abstract name for the monarchy itself, as distinct from the individual who inhabits it (that is, The Crown). A specific type of crown (or coronet for lower ranks of peerage) is employed in heraldry under strict rules. Indeed, some monarchies never had a physical crown, just a heraldic representation, as in the constitutional kingdom of Belgium.\"),\n",
    "        (\"Define destiny\", \"Destiny, sometimes also called fate (from Latin fatum 'decree, prediction, destiny, fate'), is a predetermined course of events.[1][2] It may be conceived as a predetermined future, whether in general or of an individual.\")        \n",
    "    ]\n",
    "    for i in tqdm(torch.randperm(len(train))):\n",
    "        q, a = train[i]\n",
    "        q = f\"Q: {q}\\nA: \"\n",
    "        a = f'{{\"response\": \"{a}\"}}'\n",
    "        l += train_step(q,a)\n",
    "    return l\n",
    "\n",
    "for e in tqdm(range(1)):\n",
    "    print(step())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bc63c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>{\"response\": \"0\"}\n",
      ">>>{\"response\": \"James Cameron\"}\n",
      ">>>{\"response\": \"Tom Hanks\"}\n",
      ">>>{\"response\": \"Snow White\"}\n",
      ">>>{\"response\": \"Abraham Lincoln\"}\n",
      ">>>{\"response\": \"Lyndon Baines Johnson\"}\n",
      ">>>{\"response\": \"A cat is a small, furry animal with a long tail and a\n",
      "bushy head. They are very cute and cuddly, and are often kept as\n",
      "pets.\"}\n",
      ">>>{\"response\": \"Samsung Galaxy S20.\"}\n"
     ]
    }
   ],
   "source": [
    "from textwrap import wrap \n",
    "def pgen(q,n=20): print(\">>>\"+\"\\n\".join(wrap(gen_up_to(f'Q: {q}\\nA: ', n))))\n",
    "pgen(\"I have 3 apples. I ate 1 apple. How many apples do I have left?\")\n",
    "pgen(\"Director of the movie Terminator 2\")\n",
    "pgen(\"Main male actor of Forest Gump\")\n",
    "pgen(\"Which fairytale had 7 dwarves?\")\n",
    "pgen(\"Which president of United States was assasninated?\")\n",
    "pgen(\"Name the most recent president of United States was assasninated.\")\n",
    "pgen(\"Define cat\", n=100)\n",
    "pgen(\"What is the best smartphone?\", n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fe1a6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0125, -0.0045, -0.0062,  ...,  0.0028,  0.0267, -0.0164],\n",
       "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biased.segment_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28c7365d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "3200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for z in biased.parameters():\n",
    "    if z.requires_grad:\n",
    "        print(z.numel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00615bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
